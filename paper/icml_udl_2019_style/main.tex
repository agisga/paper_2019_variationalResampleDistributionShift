%%%%%%%% ICML 2019 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2019} with \usepackage[nohyperref]{icml2019} above.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}
% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2019}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{icml2019}
\usepackage{icml2019}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
%\icmltitlerunning{Submission and Formatting Instructions for ICML UDL Workshop 2019}
\icmltitlerunning{Submission and Formatting Instructions for ICML 2019 Workshop on Uncertainty and Robustness in Deep Learning}


\begin{document}
\newcommand{\DS}{\mathcal{D}}

\twocolumn[
\icmltitle{Resampling Deep Learning model with Distribution Shift}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2019
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Aeiau Zzzz}{equal,}
\icmlauthor{Bauiu C.~Yyyy}{equal,to,goo}
\icmlauthor{Cieua Vvvvv}{goo}
\end{icmlauthorlist}

\icmlaffiliation{lmu}{Department of Computation, University of Torontoland, Torontoland, Canada}
\icmlaffiliation{tum}{Googol ShallowMind, New London, Michigan, USA}
\icmlcorrespondingauthor{Cieua Vvvvv}{c.vvvvv@googol.com}
\icmlcorrespondingauthor{Eee Pppp}{ep@eden.co.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]


\begin{abstract}
A distribution shift based resampling framework is proposed to evaluate the robustness and generalization capability of deep learning models. Auto Encoder Variational Bayes is used to find a latent representation of the data, on which Variational Gaussian Mixture Model is used to artificially create the distribution shift by dividing the dataset into different clusters. Wasserstein distance is used to characterize the extent of distribution shift between train and test data. We compare several state of art deep learning models including AC-GAN, Bayesian Convolutional Neural Network, and conventional CNN on the fashion-mnist dataset to assess their robustness under the artificially created distribution shift.
\end{abstract}

\section{Introduction}
\label{intro}
Deep Learning methods seems to be prone to corruptions and adversarial perturbations \cite{carlini2017towards}, which makes it challenging for real world applications. Distribution Shift \cite{wen2014robust} is another phenomena that can occur in practical deep learning scenarios especially medical machine learning field \cite{sun2019high}. 

Inspired from \cite{sun2019high}, which coined their work Restrictive Federated Model Selection over shifted distribution, we extend their work to image data and propose a resampling technique accordingly to evaluate how robust a model is with respect to distribution shift.
Specifically, we are interested in how model testing will behave when samples are drawn from a different distribution of the one used for training.

Our contributions are:

\begin{itemize}
\item Compared to adversarial attacks, the effect of distribution shift is not well studied in the area of deep learning. Our works evaluates how different models perform under distribution shift which serves as pioneer work in this direction.
\item We propose a resampling framework based on distribution shift to measure how robust a deep learning model, specifically a classification deep learning model is. Alongside with the Wasserstein distance we use to quantify the distribution shift. Our method should give a projected profile to a model about its robustness to distribution shift.
\end{itemize}

\section{Prerequisite}
\textbf{Auto-encoding Variational Bayes \cite{FIXME}:}\, To model the likelihood of data $p(x)$, a latent variable model $p_{\theta}(z|x)$ is approximated by a variational distribution $q_{\phi}(z|x)$ which is reparameterized to be $g(\epsilon, x)$, while the likelihood $p_{\theta}(x|z)$ can be modeled as Gaussian with mean and variance represented by decoder network. Evidence lower bound of the likelihood is optimized with stochastic gradient descent over the Monte Carlo estimation.

\textbf{AC-GAN:}\, GAN \cite{FIXME} trains a discriminator and generator network simultaneously by the mini-max game. The discriminator is trained to distinguish data from samples and generators, while the generator is trained to mimic the samples data to deteriorate the performance of the discriminator. Auxiliary Classifier GAN \cite{FIXME} augment the input of the generator network with the class label, and augment the output of the discriminator network with a classification output. Both the discriminator and the generator is trained to recover the classification output at the discriminator output side, while they optimize against the ability of the discriminator to tell apart the fake samples. 


\textbf{Bayesian Neural Network:}\, Different from generative represenation learning methods like VAE \cite{FIXME} and GAN \cite{FIXME} which models a variational approximator to the true posterior on the activation of neural network, Bayesian Neural Network build variational models on the weight of the network. \textbf{TOCONTINUE} 
 
\textbf{Variational Gaussian Mixture Model:}\,

\textbf{Wasserstein Distance:}\,

\textbf{Distribution Shift:}\, In this work, we investigate the marginal distribution shift over $p(x)$ and the class label conditional distribution shift over $p(x|C)$ where $C$ is the class label.

\section{Method}
Given a dataset $\DS$, split it into $D_{train} \bigcup D_{val} \bigcup D_{test}$. Other than a seemingly arbitrary split in most deep learning papers or random split in Cross Validation, we split it such that the each split reside in a different distribution.

Since high dimensional clustering is challenging, we first learned a representation of the whole dataset or with repsect to each class label. This gives us two benefits, one is the dimensionality reduction, and the other is we learned a latent representation that could generate new samples.

Upon the latent representation, we use Variational Gaussian Mixture model to assign each instance a different cluster. Among those, one cluster is used for training, one for validation and the left over is used for testing. A combination of the assignment to $D_{train} \bigcup D_{val} \bigcup D_{test}$ forms a variation estimate on how good a model could generalize to $D_{test}$, similar to Cross Validation.

Combined with conventional Cross Validation, our method serves as an alternative to charaterize or serves as a profile to the models' ability to generalize across distribution shift.
 
\section{Related Work}
\section{Experiment}
We use fashion-mnist \cite{FIXME} as an initial example and compare both the distribution shift on the marginal $p(x)$ and $p(x|C)$. 

Firstly, we compare our method with Cross Validation to prove emperically that Distribution Shift is indeed  a problem.

Secondly, we compare how different deep classification methods could tolerate the distribution shift.

We leave it for future work on how to amend the neural network training to tackle the distribution shift.
\section{Summary}


\bibliography{main}
\bibliographystyle{icml2019}
\appendix
\section{Acceptable to have an appendix here}
It is acceptable to include supplementary material here. 
The main text has a four-page limit. References, acknowledgements and supplementary material can exceed the four pages. 

Please submit a single PDF that contains both the main and the supplementary material. 
\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019. Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
